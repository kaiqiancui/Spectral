# src/data/cache.py
import torch
import os
import pickle

class EmbeddingCache:
    def __init__(self, cache_path):
        self.cache_path = cache_path
        self.data = self._load_cache()
        print(f"ğŸ§  Embedding Cache Loaded. Size: {len(self.data)}")

    def _load_cache(self):
        # å…¼å®¹åŸä»“åº“çš„ pickle æ ¼å¼
        with open(self.cache_path, "rb") as f:
            return pickle.load(f)

    def get_batch(self, texts):
        """
        æ ¸å¿ƒé€»è¾‘ï¼šè¾“å…¥æ–‡æœ¬åˆ—è¡¨ï¼Œè¿”å› Embedding Tensor å’Œ æœ‰æ•ˆç´¢å¼•æ©ç 
        """
        embs = []
        valid_indices = []
        
        for idx, text in enumerate(texts):
            # åŸä»“åº“é€»è¾‘æ˜¯ç›´æ¥æŸ¥å­—å…¸ï¼Œæˆ‘ä»¬è¿™é‡Œä¿æŒä¸€è‡´ï¼Œä¸è¦ææ­£åˆ™æ¸…æ´—ï¼Œç¡®ä¿ Cache å’Œ Raw Data æºå¤´ä¸€è‡´
            if text in self.data:
                embs.append(torch.tensor(self.data[text]))
                valid_indices.append(idx)
        
        if not embs:
            raise ValueError("âŒ No cache hits! Check if your cache file matches the dataset.")
            
        return torch.stack(embs), valid_indices