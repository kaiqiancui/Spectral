# ==========================================
# 实验元数据 (Meta Info)
# ==========================================
experiment:
  name: "debug_run"
  seed: 42
  device: "auto"  # "cuda:0", "cpu", or "auto"
  output_dir: "./logs"
  save_results: true

# ==========================================
# 数据配置 (Data Configuration)
# 对应原代码中的 task_name, split_method 等
# ==========================================
data:
  task_name: "Fluorescence"  # 选项: BindingDB_Ki, ESOL, Toxicity 等
  # task_name: "DAVIS"
  data_root: "./data"    # 数据集存放根目录
  cache_dir: "./cache"       # 存放处理好的 Tensor (PCA/Spectral后)
  embedding_cache_path: "/disks/sata2/kaiqian/Spectral/data/embeddings/aaseq_to_rep_store.pkl"
  # 数据划分参数
  split_method: "random"     # random, scaffold, cold_split
  split_ratio: [0.8, 0.1, 0.1] # Train/Valid/Test
  extract_batch_size: 512
  # 预处理限制
  max_smiles_length: 100
  max_protein_length: 1000

# ==========================================
# 模型配置 (LLM Configuration)
# 对应原代码中的 model_name, llama_num_b_params, load_in_4bit
# ==========================================
llm:
  model_path: "/home/gridsan/achan/experiments/LLMxFM/llama3/Meta-Llama-3-70B-Instruct-HF" # 你的模型路径
  model_type: "llama3"       # 用于区分 Prompt 模板格式
  load_in_4bit: true
  temperature: 0.1
  max_new_tokens: 10
  
  # 这里的维度需要与处理后的 Embedding 维度对齐
  # 如果不一致，代码里会自动加 Projector
  embedding_dim: 4096
  prompt_file: "chemistry/prompts/DTI_prompt_mol_pro_rep_icl.txt" 

# ==========================================
# In-Context Learning 配置
# 对应原代码中的 n_full_shots, n_representation_shots
# ==========================================
icl:
  n_total_shots: 20
  batch_size: 4
  prompt_template: "v3"      # 对应 prompt_template_version=3
  
  # ICL 策略
  sampling_strategy: "stratified" # random, stratified (KDE)
  use_representation: true   # 是否插入 Embedding

# ==========================================
# 核心方法配置 (The Method)
# 对应原代码中的 PCA, OT, DCT 等逻辑
# ==========================================
method:
  name: "spectral"  # 核心切换开关: 'identity', 'pca', 'spectral'
  
  # 如果 name='spectral'，读取这里的参数
  params:
    target_dim: 16       # 最终喂给 LLM 的向量维度 (k)
    reorder: true        # [你的创新点] 是否使用 Fiedler Vector 重排序
    add_residual: true   # [你的创新点] 是否拼接高频残差
    
    # 谱整形目标 (对齐到 Llama3 Embedding 的统计分布)
    align_stats:
      mean: 0.0
      std: 0.02