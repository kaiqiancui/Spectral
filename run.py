import os
import torch
import pandas as pd
from tqdm import tqdm
from torch.utils.data import DataLoader

# å¼•å…¥æˆ‘ä»¬é‡æ„çš„æ¨¡å—
from src.config import load_config
from src.data.loader import get_data_loader, collate_fn
from src.data.processors.factory import ProcessorFactory
from src.model.llama_wrapper import LlamaWrapper
from src.data.utils.metrics import calculate_metrics, extract_answer

def main():
    # ==========================================
    # 1. åˆå§‹åŒ–ä¸é…ç½®åŠ è½½
    # ==========================================
    cfg = load_config()
    print(f"ğŸš€ Starting Experiment: {cfg.experiment.name}")
    print(f"   Task: {cfg.data.task_name} | Method: {cfg.method.name}")
    
    device = torch.device(cfg.experiment.device if torch.cuda.is_available() else "cpu")
    os.makedirs(cfg.experiment.save_dir, exist_ok=True)

    # ==========================================
    # 2. æ•°æ®åŠ è½½ (Data Loading)
    # ==========================================
    # get_data_loader å†…éƒ¨ä½¿ç”¨äº† TaskFactory å’Œ Cache è‡ªåŠ¨å¯¹é½
    print("\nğŸ“‚ Loading Data & Aligning Caches...")
    datasets = get_data_loader(cfg)
    
    train_dataset = datasets['train']
    test_dataset = datasets['test']
    
    print(f"   Train Size: {len(train_dataset)} | Test Size: {len(test_dataset)}")

    # ==========================================
    # 3. ç‰¹å¾å¤„ç† (Processing / Alignment)
    # ==========================================
    # è¿™ä¸€æ­¥æ˜¯æ ¸å¿ƒï¼šæ— è®ºæ˜¯ Spectral è¿˜æ˜¯ Original ICRLï¼Œéƒ½åœ¨è¿™é‡ŒæŠŠ
    # åŸå§‹çš„ [N, 512] å˜ä¸ºå¯¹é½åçš„ [N, 4096]
    print(f"\nâš™ï¸ Running Processor: {cfg.method.name}...")
    processor = ProcessorFactory.get_processor(cfg)
    
    # Fit: åœ¨è®­ç»ƒé›†ä¸Šè®¡ç®—ç»Ÿè®¡é‡ (å¦‚ Mean, Std, Fiedler Vector, PCA Matrix)
    processor.fit(train_dataset)
    
    # Transform: å°†å˜æ¢åº”ç”¨åˆ°è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    # æ³¨æ„ï¼šè¿™ä¼šç›´æ¥ä¿®æ”¹ dataset å†…éƒ¨çš„ input1_emb ç­‰å­—æ®µï¼Œæˆ–è€…è¿”å›æ–°çš„ Tensor
    # å»ºè®® processor å†…éƒ¨å®ç° update_dataset æ–¹æ³•
    processor.transform_dataset(train_dataset)
    processor.transform_dataset(test_dataset)
    
    print("   âœ… Processing Complete. Embeddings are now aligned to LLM space.")

    # ==========================================
    # 4. å‡†å¤‡ DataLoader
    # ==========================================
    # Process ä¹‹åå†å»ºç«‹ Loaderï¼Œå› ä¸º Tensor å·²ç»å˜äº†
    test_loader = DataLoader(
        test_dataset, 
        batch_size=cfg.icl.batch_size, 
        shuffle=False, 
        collate_fn=collate_fn # éœ€ç¡®ä¿ collate_fn èƒ½å¤„ç† input1_emb
    )

    # ==========================================
    # 5. æ¨¡å‹åˆå§‹åŒ– (Model Initialization)
    # ==========================================
    print(f"\nğŸ¤– Initializing Llama Wrapper...")
    model = LlamaWrapper(cfg).to(device)
    model.eval()

    # ==========================================
    # 6. æ¨ç†å¾ªç¯ (Inference Loop)
    # ==========================================
    print("\nğŸ”® Starting Inference...")
    all_preds = []
    all_targets = []
    results_log = []

    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Evaluating"):
            # batch å·²ç»åœ¨ collate_fn é‡Œè¢«å¤„ç†æˆ Tensor (å¦‚æœæ˜¯ embedding)
            
            # ç”Ÿæˆæ–‡æœ¬
            outputs = model.generate(batch)
            
            # åå¤„ç†ä¸è¯„ä¼°
            targets = batch['label'] # å‡è®¾ dataset è¿”å› label
            
            for i, text in enumerate(outputs):
                # æå–æ•°å€¼ç­”æ¡ˆ
                pred_val = extract_answer(text)
                target_val = targets[i]
                
                all_preds.append(pred_val)
                all_targets.append(target_val)
                
                results_log.append({
                    "target": target_val,
                    "prediction": pred_val,
                    "output_text": text
                })

    # ==========================================
    # 7. ç»“æœä¿å­˜ä¸è®¡ç®— (Metrics)
    # ==========================================
    print("\nğŸ“ˆ Calculating Metrics...")
    # è¿‡æ»¤æ— æ•ˆé¢„æµ‹ (None)
    valid_preds = [p if p is not None else 0.0 for p in all_preds]
    
    metrics = calculate_metrics(valid_preds, all_targets)
    metrics['valid_rate'] = sum(1 for p in all_preds if p is not None) / len(all_preds)
    
    print("="*40)
    print(f"RMSE: {metrics.get('rmse', 'N/A')}")
    print(f"Pearson: {metrics.get('pearson', 'N/A')}")
    print(f"Valid Rate: {metrics['valid_rate']:.2%}")
    print("="*40)
    
    # ä¿å­˜ç»“æœ
    res_path = os.path.join(cfg.experiment.save_dir, "results.csv")
    pd.DataFrame(results_log).to_csv(res_path, index=False)
    print(f"ğŸ’¾ Results saved to {res_path}")

if __name__ == "__main__":
    main()