import torch
from torch.utils.data import DataLoader
from tqdm import tqdm
import os
import numpy as np
import pandas as pd

# å¼•å…¥æˆ‘ä»¬çš„æ¨¡å—
from src.config import load_config
from src.data.dataset import UnifiedICLDataset, collate_fn
from src.model.components import RandomProjector
from src.model.llama_wrapper import LlamaWrapper
from src.utils.metrics import extract_answer, calculate_metrics

def compute_alignment_stats(model, projector, train_loader, device, max_samples=2000):
    """
    [æ ¸å¿ƒé€»è¾‘] è®¡ç®—å¯¹é½å‚æ•°
    æ— éœ€è®­ç»ƒï¼Œåªéœ€è®¡ç®—ç»Ÿè®¡é‡ (Mean, Std)
    """
    print("ğŸ“Š Computing Alignment Statistics (Training-Free)...")
    
    # 1. è®¡ç®—ç›®æ ‡åˆ†å¸ƒ (Target Stats) - æ¥è‡ª LLM è‡ªèº«çš„ Embedding
    # è·å– LLM çš„ Embedding æƒé‡çŸ©é˜µ
    llm_embeddings = model.llm.get_input_embeddings().weight.detach() # (Vocab, 4096)
    
    # è¿‡æ»¤æ‰ padding ç­‰é›¶å‘é‡ (å‚è€ƒåŸè®ºæ–‡é€»è¾‘)
    non_zero_mask = torch.abs(llm_embeddings).sum(dim=1) > 1e-9
    valid_llm_embeds = llm_embeddings[non_zero_mask]
    
    target_mean = valid_llm_embeds.mean().item()
    target_std = valid_llm_embeds.std().item()
    
    print(f"   Target (LLM) Mean: {target_mean:.6f}, Std: {target_std:.6f}")
    
    # 2. è®¡ç®—æºåˆ†å¸ƒ (Source Stats) - æ¥è‡ªæˆ‘ä»¬çš„ Projector è¾“å‡º
    # æˆ‘ä»¬éœ€è¦è·‘ä¸€éƒ¨åˆ†è®­ç»ƒæ•°æ®ï¼Œç»è¿‡ Projectorï¼Œçœ‹çœ‹åˆ†å¸ƒé•¿å•¥æ ·
    source_embeds_bucket = []
    sample_count = 0
    
    for batch in tqdm(train_loader, desc="Calibrating"):
        # å–å‡º embedding: (Batch, 640)
        embs = batch['net_input']['query_emb'].to(device).to(model.llm.dtype)
        
        # ç»è¿‡éšæœºæŠ•å½±: (Batch, 640) -> (Batch, 4096)
        with torch.no_grad():
            proj_embs = projector(embs)
            
        source_embeds_bucket.append(proj_embs)
        sample_count += len(embs)
        if sample_count >= max_samples:
            break
            
    all_source_embs = torch.cat(source_embeds_bucket, dim=0)
    
    # å¯¹é½ç»Ÿè®¡é‡ç»“æ„ä½“
    align_stats = {
        'target_mean': torch.tensor(target_mean, device=device),
        'target_std': torch.tensor(target_std, device=device),
        'source_mean': all_source_embs.mean(), # è¿™é‡Œå¯ä»¥æ›´ç²¾ç»†åœ°æŒ‰ç»´åº¦ç®—ï¼ŒåŸè®ºæ–‡é€šå¸¸æ˜¯å…¨å±€ç®—
        'source_std': all_source_embs.std()
    }
    
    print(f"   Source (Proj) Mean: {align_stats['source_mean']:.6f}, Std: {align_stats['source_std']:.6f}")
    
    return align_stats

def main():
    # 1. åŠ è½½é…ç½®
    cfg = load_config()
    print(f"ğŸš€ Starting ICRL Inference: {cfg.experiment.name}")
    print(f"   Task: {cfg.data.task_name} | Model: {cfg.llm.model_path}")
    
    device = torch.device(cfg.experiment.device if torch.cuda.is_available() else "cpu")
    
    # 2. åŠ è½½æ•°æ®
    data_path = os.path.join(cfg.data.get("data_root", "./data"), "processed_data.pt")
    # å¦‚æœ preprocess ä¿å­˜è·¯å¾„ä¸ä¸€æ ·ï¼Œè¯·åœ¨è¿™é‡Œä¿®æ”¹ï¼Œæˆ–è€…ä» cfg.experiment.save_dir è¯»å–
    # å‡è®¾ preprocess.py ä¿å­˜åˆ°äº† logs/... ä¸‹ï¼Œä¸ºäº†æ–¹ä¾¿æˆ‘ä»¬å…ˆè¯•æ¢æ€§è¯»å–
    if not os.path.exists(data_path):
        # å°è¯•ä» logs ç›®å½•æ‰¾
        data_path = os.path.join(cfg.experiment.save_dir, "processed_data.pt")
        
    print(f"ğŸ“‚ Reading data from: {data_path}")
    
    # è®­ç»ƒé›†ç”¨äºæä¾› Shots å’Œ æ ¡å‡†åˆ†å¸ƒ
    train_dataset = UnifiedICLDataset(data_path, n_shots=cfg.icl.n_total_shots, mode='train')
    # æµ‹è¯•é›†ç”¨äºè¯„ä¼°
    test_dataset = UnifiedICLDataset(data_path, n_shots=cfg.icl.n_total_shots, mode='test')
    
    # DataLoader
    # æ ¡å‡†ä¸éœ€è¦ shuffleï¼Œä¹Ÿä¸éœ€è¦ shotsï¼Œåªå– query_emb å³å¯ï¼Œä½†å¤ç”¨ collate_fn æ–¹ä¾¿
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)
    test_loader = DataLoader(test_dataset, batch_size=cfg.icl.batch_size, shuffle=False, collate_fn=collate_fn)
    
    # 3. åˆå§‹åŒ–ç»„ä»¶
    # è‡ªåŠ¨æ£€æµ‹è¾“å…¥ç»´åº¦ (ä»æ•°æ®é›†é‡Œæ‹¿ä¸€ä¸ªçœ‹çœ‹)
    sample_emb = train_dataset[0]['query']['emb']
    input_dim = sample_emb.shape[0] # é€šå¸¸æ˜¯ 640 (ESM-2 150M) æˆ– 1280
    output_dim = 4096 # Llama-3 8B hidden size
    
    print(f"ğŸ”§ Initializing Projector: {input_dim} -> {output_dim}")
    projector = RandomProjector(input_dim, output_dim).to(device)
    
    # åŠ è½½ Llama
    model = LlamaWrapper(cfg, projector).to(device)
    
    # 4. [Phase 1] ç»Ÿè®¡å¯¹é½ (Calibration)
    align_stats = compute_alignment_stats(model, projector, train_loader, device)
    
    # 5. [Phase 2] æ¨ç†è¯„ä¼° (Inference)
    print("\nğŸ”® Starting Inference on Test Set...")
    all_preds = []
    all_targets = []
    
    # åˆ›å»ºç»“æœä¿å­˜ç›®å½•
    res_dir = os.path.join(cfg.experiment.save_dir, "results")
    os.makedirs(res_dir, exist_ok=True)
    f_log = open(os.path.join(res_dir, "predictions.txt"), "w")
    
    for batch in tqdm(test_loader, desc="Testing"):
        net_input = batch['net_input']
        targets = batch['target'].numpy()
        
        # ç”Ÿæˆæ–‡æœ¬
        # æ³¨æ„ï¼šgenerate å†…éƒ¨ä¼šè‡ªåŠ¨è°ƒç”¨ projector å’Œ apply_alignment
        decoded_outputs = model.generate(net_input, align_stats=align_stats)
        
        for i, text in enumerate(decoded_outputs):
            # æå–æ•°å€¼
            pred_val = extract_answer(text)
            
            all_preds.append(pred_val)
            all_targets.append(targets[i])
            
            # å®æ—¶æ‰“å°/ä¿å­˜æ—¥å¿—
            # Llama3 çš„è¾“å‡ºå¯èƒ½åŒ…å« promptï¼Œæˆ‘ä»¬éœ€è¦æˆªå– assistant çš„éƒ¨åˆ†
            # ç”±äº decode_outputs æ˜¯çº¯ç”Ÿæˆçš„æ–‡æœ¬ï¼ˆå¦‚æœä½¿ç”¨ model.generate çš„è¯ï¼‰
            # æˆ–è€…åŒ…å« promptï¼ˆå¦‚æœé…ç½®ä¸åŒï¼‰ã€‚
            # è¿™é‡Œçš„ LlamaWrapper.generate è¿”å›çš„æ˜¯çº¯ç”Ÿæˆçš„æ–‡æœ¬éƒ¨åˆ†å—ï¼Ÿ
            # æ£€æŸ¥ LlamaWrapper ä»£ç : tokenizer.batch_decode(outputs) ä¼šåŒ…å«æ‰€æœ‰ input_ids
            # æ‰€ä»¥æˆ‘ä»¬éœ€è¦æˆªå–ã€‚
            
            # ç®€å•å¤„ç†ï¼šæå– prompt ä¹‹åçš„æ–‡æœ¬
            # æ›´å¥½çš„åšæ³•æ˜¯åœ¨ LlamaWrapper é‡Œåª decode æ–°ç”Ÿæˆçš„ token
            # å‡è®¾ metrics.extract_answer è¶³å¤Ÿé²æ£’èƒ½å¤„ç†å…¨æ–‡
            
            log_str = f"GT: {targets[i]:.4f} | Pred: {pred_val} | Raw: {text[-50:].replace(chr(10), ' ')}"
            f_log.write(log_str + "\n")
            
            # ç®€å• debug
            if i == 0:
                print(f"\n[Sample Output]\n{text[-100:]}\n--> Parsed: {pred_val}")

    f_log.close()
    
    # 6. è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
    print("\nğŸ“ˆ Calculating Metrics...")
    metrics = calculate_metrics(all_preds, all_targets)
    
    print("="*40)
    print(f"Experiment: {cfg.experiment.name}")
    print(f"RMSE: {metrics['rmse']:.4f}")
    print(f"Pearson: {metrics['pearson']:.4f}")
    print(f"Spearman: {metrics['spearman']:.4f}")
    print(f"Valid Outputs: {metrics['valid_count']}/{metrics['total_count']}")
    print("="*40)
    
    # ä¿å­˜æŒ‡æ ‡
    pd.DataFrame([metrics]).to_csv(os.path.join(res_dir, "metrics.csv"), index=False)

if __name__ == "__main__":
    main()